{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "313d807c-bfb0-4767-b7b5-d54416d381fe",
      "metadata": {
        "id": "313d807c-bfb0-4767-b7b5-d54416d381fe"
      },
      "source": [
        "# 1.DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edcb5487-e2a4-4568-9598-8f7781b8b77f",
      "metadata": {
        "id": "edcb5487-e2a4-4568-9598-8f7781b8b77f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from datetime import datetime as dt\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "015155f2-8d04-47b9-bf7e-a98213452a13",
      "metadata": {
        "id": "015155f2-8d04-47b9-bf7e-a98213452a13"
      },
      "outputs": [],
      "source": [
        "with open ('sx-stackoverflow-a2q.txt') as dataset_a2q:\n",
        "    a2q=dataset_a2q.readlines()\n",
        "\n",
        "with open ('sx-stackoverflow-c2a.txt') as dataset_c2a:\n",
        "    c2a= dataset_c2a.readlines()\n",
        "    \n",
        "with open ('sx-stackoverflow-c2q.txt') as dataset_c2q:\n",
        "    c2q= dataset_c2q.readlines()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e4e9a10-c1ed-43fd-843a-8ccb8881be14",
      "metadata": {
        "id": "1e4e9a10-c1ed-43fd-843a-8ccb8881be14"
      },
      "source": [
        "### Preparing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b5735e7-b3fb-46b1-a09d-a7723115ee25",
      "metadata": {
        "id": "4b5735e7-b3fb-46b1-a09d-a7723115ee25"
      },
      "source": [
        "Note that we're changing the values of the read data instead of creating new variables to store the corrected version, in order to save space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3864a1e-2ad9-475c-b9f2-f51b6cdb648e",
      "metadata": {
        "id": "c3864a1e-2ad9-475c-b9f2-f51b6cdb648e"
      },
      "outputs": [],
      "source": [
        "n=10000 #we'll try first with n=100 rows from each one of the 3 datasets\n",
        "for i in range(0,n):\n",
        "    a2q[i]=a2q[i].split()\n",
        "    a2q[i][0]=int(a2q[i][0])\n",
        "    a2q[i][1]=int(a2q[i][1])\n",
        "    a2q[i][2]=dt.utcfromtimestamp(int(a2q[i][2])).strftime('%Y-%m-%d')\n",
        "    \n",
        "for i in range(0,n):\n",
        "    c2a[i]=c2a[i].split()\n",
        "    c2a[i][0]=int(c2a[i][0])\n",
        "    c2a[i][1]=int(c2a[i][1])\n",
        "    c2a[i][2]=dt.utcfromtimestamp(int(c2a[i][2])).strftime('%Y-%m-%d')\n",
        "    \n",
        "for i in range(0,n):\n",
        "    c2q[i]=c2q[i].split()\n",
        "    c2q[i][0]=int(c2q[i][0])\n",
        "    c2q[i][1]=int(c2q[i][1])\n",
        "    c2q[i][2]=dt.utcfromtimestamp(int(c2q[i][2])).strftime('%Y-%m-%d')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4bca102",
      "metadata": {
        "id": "e4bca102"
      },
      "source": [
        "## Faster version, but gives memory error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e466e8d",
      "metadata": {
        "id": "5e466e8d"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "with open ('sx-stackoverflow-a2q.txt') as dataset_a2q:\n",
        "    a2q = [int(x) for x in dataset_a2q.read().split()] #while reading lines, split and transform into int\n",
        "    #len(lst)=3* real number of lines, because after this step each value is stored alone: no nested lists\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e061d348",
      "metadata": {
        "id": "e061d348"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "m=int(len(a2q)/3)\n",
        "for i in range(2,m+1,3):\n",
        "    a2q[i]=dt.utcfromtimestamp(a2q[i]).strftime('%Y-%m-%d')\n",
        "    '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6866441b",
      "metadata": {
        "id": "6866441b"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "with open ('sx-stackoverflow-c2a.txt') as dataset_c2a:\n",
        "    c2a = [int(x) for x in dataset_c2a.read().split()]\n",
        "    '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4cde396",
      "metadata": {
        "id": "f4cde396"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "m=int(len(c2a)/3)\n",
        "for i in range(2,m+1,3):\n",
        "    c2a[i]=dt.utcfromtimestamp(c2a[i]).strftime('%Y-%m-%d')\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d839bf5",
      "metadata": {
        "id": "3d839bf5"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "with open ('sx-stackoverflow-c2q.txt') as dataset_c2q:\n",
        "    c2q = [int(x) for x in dataset_c2q.read().split()]\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab9040c2",
      "metadata": {
        "id": "ab9040c2"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "m=int(len(c2q)/3)\n",
        "for i in range(2,m+1,3):\n",
        "    c2q[i]=dt.utcfromtimestamp(c2q[i]).strftime('%Y-%m-%d')\n",
        "    '''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e57bf5fb-60ac-4ca3-b589-b6b7aa2d3a60",
      "metadata": {
        "id": "e57bf5fb-60ac-4ca3-b589-b6b7aa2d3a60"
      },
      "source": [
        "### Remove answer from user to his own question, i.e. remove loops from corresponding graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7477426f",
      "metadata": {
        "id": "7477426f"
      },
      "outputs": [],
      "source": [
        "a2q_n=a2q[0:n]\n",
        "c2a_n=c2a[0:n]\n",
        "c2q_n=c2q[0:n]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97f0f7d4-a147-490e-a80f-625550d3daf8",
      "metadata": {
        "id": "97f0f7d4-a147-490e-a80f-625550d3daf8"
      },
      "outputs": [],
      "source": [
        "w=0\n",
        "while w<len(a2q_n):\n",
        "    if a2q_n[w][0]==a2q_n[w][1]:\n",
        "        del a2q_n[w]\n",
        "    else:\n",
        "        w+=1\n",
        "naq=len(a2q_n)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71261cdf-093b-47d1-985d-ed9eeefba444",
      "metadata": {
        "id": "71261cdf-093b-47d1-985d-ed9eeefba444"
      },
      "source": [
        "### Should do the same for the other 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e48006d7-9c6e-4757-a458-0c69c8e76889",
      "metadata": {
        "id": "e48006d7-9c6e-4757-a458-0c69c8e76889"
      },
      "outputs": [],
      "source": [
        "x=0\n",
        "while x<len(c2a_n):\n",
        "    if c2a_n[x][0]==c2a_n[x][1]:\n",
        "        del c2a_n[x]\n",
        "    else:\n",
        "        x+=1\n",
        "nca=len(c2a_n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "165aa557",
      "metadata": {
        "id": "165aa557",
        "outputId": "b41724c2-3f44-4f4d-b07d-893080306664"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8319"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(c2a_n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fde7540-072c-4579-8af4-24d9739a9433",
      "metadata": {
        "id": "9fde7540-072c-4579-8af4-24d9739a9433"
      },
      "outputs": [],
      "source": [
        "y=0\n",
        "while y<len(c2q_n):\n",
        "    if c2q_n[y][0]==c2q_n[y][1]:\n",
        "        del c2q_n[y]\n",
        "    else:\n",
        "        y+=1\n",
        "ncq=len(c2q_n)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bf70e69-6d3f-4d60-a549-df2ca701befc",
      "metadata": {
        "id": "8bf70e69-6d3f-4d60-a549-df2ca701befc"
      },
      "source": [
        "## NOW CREATE WEIGHTED GRAPH ??"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "826ed072-9772-424b-bf51-80567683222f",
      "metadata": {
        "id": "826ed072-9772-424b-bf51-80567683222f"
      },
      "source": [
        "### We'll use a nested dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e25ee4cc",
      "metadata": {
        "id": "e25ee4cc"
      },
      "outputs": [],
      "source": [
        "def dateInRange(date, initTime, endTime): #return true if the given date its in the range [initTime, endTime], return false otherwise\n",
        "    if(initTime == '-' or endTime == '-'):\n",
        "        return True\n",
        "    if initTime <= date <= endTime:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "    \n",
        "def createGraph(initTime, endTime, data):\n",
        "    graph = {}\n",
        "    for x in range(len(data)):\n",
        "        if dateInRange(data[x][2], initTime, endTime):\n",
        "            if data[x][0] in graph: #we already have the node of that user in the graph\n",
        "                if data[x][1] in graph[data[x][0]]: #we already have one interaction of user data[x][0] with user data[x][1], so we add 1 to the number of interactions\n",
        "                    graph[data[x][0]][data[x][1]]['weight'] += 1\n",
        "                else:\n",
        "                    graph[data[x][0]][data[x][1]] = {'weight': 1} #we don't have an interacion between that 2 users, so we initialize the interaction with a 1 (because till the moment we only have 1 interaction).\n",
        "            else: #we don't have the node of the user in the graph\n",
        "                graph[data[x][0]] = {data[x][1] : {'weight': 1}}\n",
        "    return graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4eb0879c",
      "metadata": {
        "id": "4eb0879c"
      },
      "outputs": [],
      "source": [
        "#a2q_n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b35cee1d",
      "metadata": {
        "id": "b35cee1d"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "auxData = [['0','1','2008-02-11'], ['0', '2', '2008-02-11'], ['0', '1', '2008-02-11'], ['1','0', '2008-04-11']]\n",
        "dict_a2q_n = createGraph('2008-02-11', '2008-02-11', auxData)\n",
        "dict_a2q_n\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6df7b108",
      "metadata": {
        "id": "6df7b108"
      },
      "outputs": [],
      "source": [
        "dict_a2q_n = createGraph('-', '-', a2q_n)\n",
        "dict_c2a_n = createGraph('-', '-', c2a_n)\n",
        "dict_c2q_n = createGraph('-', '-', c2q_n)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3164d84a",
      "metadata": {
        "id": "3164d84a"
      },
      "outputs": [],
      "source": [
        "#dict_a2q_n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b1b83a1-76eb-46fd-8640-dc5f010e01a6",
      "metadata": {
        "id": "3b1b83a1-76eb-46fd-8640-dc5f010e01a6"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "dict_a2q_n={}\n",
        "for i in range (0,naq):\n",
        "    dict_a2q_n[a2q_n[i][0]]={'a2vs_question':a2q_n[0][1],'time_a2q':a2q_n[0][2],'weight':0}\n",
        "    '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2383626-83a7-48d2-b6e6-2196bd1baa3b",
      "metadata": {
        "id": "c2383626-83a7-48d2-b6e6-2196bd1baa3b"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "dict_c2a_n={}\n",
        "for i in range (0,nca):\n",
        "    dict_c2a_n[c2a_n[i][0]]={'c2vs_answer':c2a_n[0][1],'time_c2a':c2a_n[0][2],'weight':0}\n",
        "    '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee5ac4e5-614f-4b9b-a890-8f045bd26946",
      "metadata": {
        "id": "ee5ac4e5-614f-4b9b-a890-8f045bd26946"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "dict_c2q_n={}\n",
        "for i in range (0,ncq):\n",
        "    dict_c2q_n[c2q_n[i][0]]={'c2vs_question':c2q_n[0][1],'time_c2q':c2q_n[0][2],'weight':0}\n",
        "    '''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "911ea805-30b0-44cb-8641-c83b29a3daf8",
      "metadata": {
        "id": "911ea805-30b0-44cb-8641-c83b29a3daf8"
      },
      "source": [
        "#### For the merged dataset: -----> to work on, according to how we decide to merge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0b870b6",
      "metadata": {
        "id": "f0b870b6"
      },
      "outputs": [],
      "source": [
        "def mergeTwoGraphs(g1, g2): #merge g1 and g2 into one graph. g1 and g2 must exist.\n",
        "    #  print(\\\"-----------\\\")\n",
        "    #  print(\\\"g1: \\\", g1)\n",
        "    #  print(\\\"g2: \\\", g2)\n",
        "    #  print(\\\"-----------\\\")\n",
        "    for x in g2:\n",
        "        #print(\\\"x: \\\", x)\n",
        "        if x in g1: #if in g1 we have the user x, we have to add all his interactions 1 by 1. If the interaction already exists, we just add 1 to the weight.\n",
        "            for y in g2[x]:\n",
        "                #print(\\\"y: \\\", y)\n",
        "                if y in g1[x]:\n",
        "                    g1[x][y]['weight'] += g2[x][y]['weight']\n",
        "                else:\n",
        "                    g1[x][y] = {'weight': 1}\n",
        "        else: #if in g1 we don't have the user x, we add all his interactions\n",
        "            g1[x] = g2[x]\n",
        "    return g1\n",
        "    \n",
        "def mergeGraphs(graphs): #merge the graphs into one graph. The parameter graphs it's and array of all the graphs to merge [g1, g2, ...]\n",
        "        mergedGraph = {}\n",
        "        if len(graphs) > 0:\n",
        "            mergedGraph = graphs[0]\n",
        "            for x in graphs[1:]:\n",
        "                mergedGraph = mergeTwoGraphs(mergedGraph, x)       \n",
        "        return mergedGraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cd8181a",
      "metadata": {
        "id": "9cd8181a"
      },
      "outputs": [],
      "source": [
        "merged_Graphs = mergeGraphs([dict_a2q_n,dict_c2a_n,dict_c2q_n])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab982ef7",
      "metadata": {
        "id": "ab982ef7"
      },
      "outputs": [],
      "source": [
        "#merged_Graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f97aa6b-df17-4b3e-b0dc-b9db546db35c",
      "metadata": {
        "id": "6f97aa6b-df17-4b3e-b0dc-b9db546db35c"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "dict_merged={}\n",
        "dict_merged.update(dict_a2q_n)\n",
        "for i in dict_c2a_n.keys():\n",
        "    if i not in dict_merged.keys():\n",
        "        dict_merged[i]={'c2vs_answer':c2a_n[0][1],'time_c2a':c2a_n[0][2],'weight':0}\n",
        "for j in dict_c2q_n.keys():\n",
        "    if j not in dict_merged.keys(): \n",
        "        dict_merged[j]={'c2vs_question':c2q_n[0][1],'time_c2q':c2q_n[0][2],'weight':0}\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "974728f4-f04a-4486-a8f6-b0fef5c4a090",
      "metadata": {
        "id": "974728f4-f04a-4486-a8f6-b0fef5c4a090"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "for key in dict_merged.keys():\n",
        "    if len(dict_merged[key])>3:\n",
        "        print(i)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HQvvnnPB9EVE",
      "metadata": {
        "id": "HQvvnnPB9EVE"
      },
      "source": [
        "#### Functionalities are defined as methods within a class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kTxI0kd17ZA3",
      "metadata": {
        "id": "kTxI0kd17ZA3"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from heapq import heappush, heappop\n",
        "from itertools import count\n",
        "import networkx as nx\n",
        "# MYGRAPH = {'A': {'B': 2, 'C': 3}, 'B': {'A': 2, 'C': 5}, 'C':{'A':3, 'B':5, 'D': 10}}\n",
        "\n",
        "MYGRAPH = {'A':{'B':5, 'C':3, 'D':4}, 'B':{'A':5, 'D':1}, 'C':{'A':3,'E':5}, 'D':{'A':4, 'B':1, 'E':2}}\n",
        "\n",
        "# MYGRAPH = nx.erdos_renyi_graph(50,0.5)\n",
        "# MYGRAPH is feed into the class in static way\n",
        "# MYGRAPH is the merged graph and we need a function that returns the merged graph between two time intervals\n",
        "class Graphs:\n",
        "    def __init__(self, i):\n",
        "        # <i> should be used in visualization phase.\n",
        "        # We call each functionality (method) within the class according to\n",
        "        # the given <i> by the user.\n",
        "        self.i = i\n",
        "        self.results = []\n",
        "        self.init_graph = MYGRAPH\n",
        "        self.nx_graph = self.construct_nx_graph()\n",
        "\n",
        "    # First functionality\n",
        "    def get_features(self, inp_graph):\n",
        "\n",
        "        # Checking if the graph is undirected or not by looking for\n",
        "        # similar edges between pairs of vertices.\n",
        "        def is_directed():\n",
        "            for u, neigh in inp_graph.items():\n",
        "                for n in neigh.items():\n",
        "                    if n[0] in inp_graph:\n",
        "                        if n[0] != u and not ([(node, w) for node, w in inp_graph[n[0]].items() if (node == u and w == n[1])]):\n",
        "                            # print(\"The graph is directed\")\n",
        "                            return 1\n",
        "            # print(\"The graph is undirected.\")\n",
        "            return 0\n",
        "\n",
        "        # Number of users is equal to all the unique values both in keys\n",
        "        # and values of the given graph in the format of a dictionary.\n",
        "        def num_of_users():\n",
        "            _users = []\n",
        "            for k, v in inp_graph.items():\n",
        "                _users.append(k)\n",
        "                for i in [*v]:\n",
        "                    _users.append(i)\n",
        "            return len(set(_users))\n",
        "\n",
        "        # Counting all the values of the sub-dictionaries. If the graph is undirected\n",
        "        # then we divide the result by two.\n",
        "        def num_ans():\n",
        "            _counter = 0\n",
        "            for i in inp_graph.values():\n",
        "                _counter += len(i)\n",
        "            if self.results[0] == 0:\n",
        "                return _counter/2\n",
        "            else:\n",
        "                return _counter\n",
        "\n",
        "        # Number of edges / number of vertices\n",
        "        def avg_links():\n",
        "            return self.results[2]/self.results[1]\n",
        "\n",
        "        # Two different scenarios based on whether the graph is directed\n",
        "        # or not\n",
        "        def density_degree():\n",
        "            if self.results[0] == 1:\n",
        "                _density = self.results[2] / (self.results[1]*(self.results[1] - 1))\n",
        "            else:\n",
        "                _density = 2 * self.results[2] / (self.results[1] * (self.results[1] - 1))\n",
        "            return _density\n",
        "\n",
        "        # if density < 0.5 then it is sparse; otherwise it is considered dense.\n",
        "        def sparsity():\n",
        "            if self.results[4] <= 0.5:\n",
        "                # print(\"Sparse!\")\n",
        "                return 0\n",
        "            else:\n",
        "                # print(\"Dense!\")\n",
        "                return 1\n",
        "\n",
        "        self.results.append(is_directed())\n",
        "        self.results.append(num_of_users())\n",
        "        self.results.append(num_ans())\n",
        "        self.results.append(avg_links())\n",
        "        self.results.append(density_degree())\n",
        "        self.results.append(sparsity())\n",
        "\n",
        "        return self.results\n",
        "\n",
        "    # Making the graph dictionary symmetrical\n",
        "    def construct_nx_graph(self):\n",
        "\n",
        "        for k, v in self.init_graph.items():\n",
        "            for index in v:\n",
        "                v[index] = {'weight': v[index]}\n",
        "        temp_graph = nx.DiGraph(self.init_graph)\n",
        "        temp_graph.add_nodes_from(self.init_graph.keys())\n",
        "\n",
        "        return temp_graph\n",
        "\n",
        "    # Now we have the base for functionality #2\n",
        "    def best_user(self, t_node):   #def best_user(self, t_node, init_time, end_time)\n",
        "        # The section about graph merging needs to be reconsidered\n",
        "        # We need to define a function\n",
        "\n",
        "        # Extracting the desired graph between init_time and end_time here:\n",
        "        ######################  Getting Output Graph  #####################\n",
        "        # trimmed_graph = FUNCTION(init_time, end_time)\n",
        "        # then replace self.nx_graph with trimmed_graph\n",
        "\n",
        "        def betweeness():\n",
        "\n",
        "            btwns = dict.fromkeys(self.nx_graph, 0.0)\n",
        "            # s is the source\n",
        "            S = []      # The shortest path\n",
        "            P = {}      # The previous node in the shortest path\n",
        "\n",
        "            # Initializing the previous path of each node as null\n",
        "            for v in self.nx_graph:\n",
        "                P[v] = []\n",
        "            # Having a pure list of nodes in a dict with value of 0 of each unseen node and 1 for each seen one\n",
        "            temp_dict = dict.fromkeys(self.nx_graph, 0.0)\n",
        "            D = {}\n",
        "            temp_dict[t_node] = 1.0      # Making the source node as seen\n",
        "            Q = []  # out heap\n",
        "            temp_push = heappush\n",
        "            temp_pop = heappop\n",
        "            seen = {t_node: 0}\n",
        "            c = count()\n",
        "            temp_push(Q, (0, next(c), t_node, t_node))\n",
        "            while Q:\n",
        "                (distance, _, pred, v) = temp_pop(Q)\n",
        "                if v in D:\n",
        "                    continue  # already searched this node.\n",
        "                temp_dict[v] += temp_dict[pred]  # Counting the number of paths\n",
        "                S.append(v)\n",
        "                D[v] = distance\n",
        "                for w, edges in self.nx_graph[v].items():\n",
        "                    vw_dist = distance + edges.get('weight', 1)\n",
        "                    if w not in D and (w not in seen or vw_dist < seen[w]):\n",
        "                        seen[w] = vw_dist\n",
        "                        temp_push(Q, (vw_dist, next(c), v, w))\n",
        "                        temp_dict[w] = 0.0\n",
        "                        P[w] = [v]\n",
        "                    elif vw_dist == seen[w]:  # handle equal paths\n",
        "                        temp_dict[w] += temp_dict[v]\n",
        "                        P[w].append(v)\n",
        "\n",
        "            # Then we accumulate the results of the Dijkstra without having any target (sink) node\n",
        "            d_t = dict.fromkeys(S, 0)\n",
        "            while S:\n",
        "                t1 = S.pop()\n",
        "                _coeffs = (1 + d_t[t1]) / temp_dict[t1]\n",
        "                for node in P[t1]:\n",
        "                    d_t[node] += temp_dict[node] * _coeffs\n",
        "                if t1 != t_node:\n",
        "                    btwns[t1] += d_t[t1]\n",
        "\n",
        "            return btwns\n",
        "\n",
        "        return (betweeness())\n",
        "\n",
        "\n",
        "\n",
        "# Testing with both directed and undirected (dense) graphs\n",
        "# uncomment for directed graph\n",
        "# my_dict = {'A': {'B': 2, 'C': 3}, 'B': {'A': 4, 'C': 5, 'D':10}}\n",
        "# uncomment for undirected graph\n",
        "# my_dict = {'A': {'B': 2, 'C': 3}, 'B': {'A': 2, 'C': 5}, 'C':{'A':3, 'B':5}}\n",
        "\n",
        "# i = 1 indicates functionality 1\n",
        "# graph_features = Graphs(1)\n",
        "# report = graph_features.get_features(my_dict)\n",
        "# print(report)\n",
        "\n",
        "#g = Graphs(1)\n",
        "#print(g.best_user('C'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ef590c5-0a5b-4593-92a5-cf0cd4a8f983",
      "metadata": {
        "id": "2ef590c5-0a5b-4593-92a5-cf0cd4a8f983"
      },
      "outputs": [],
      "source": [
        "my_dict = {'A': {'B':{'weight': 2}, 'C':{'weight': 3}}, 'B': {'A':{'weight': 4}, 'C':{'weight': 5}, 'D':{'weight': 10}}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e5093da-d50b-4756-81b4-efe4803ad1ec",
      "metadata": {
        "id": "9e5093da-d50b-4756-81b4-efe4803ad1ec"
      },
      "outputs": [],
      "source": [
        "r=nx.Graph(my_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee2b52e8-ac49-4073-9593-93c8973b44c6",
      "metadata": {
        "id": "ee2b52e8-ac49-4073-9593-93c8973b44c6"
      },
      "outputs": [],
      "source": [
        "r.nodes()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fac452b7-fc31-4d0e-b021-0d02e86ad7e5",
      "metadata": {
        "id": "fac452b7-fc31-4d0e-b021-0d02e86ad7e5"
      },
      "source": [
        "# FUNCTIONALITY 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b654b193-91f7-4049-a8f6-2ff9f6eed7c0",
      "metadata": {
        "id": "b654b193-91f7-4049-a8f6-2ff9f6eed7c0"
      },
      "outputs": [],
      "source": [
        "def dijkstra(g,start,end):\n",
        "    s=start\n",
        "    route=[]\n",
        "    #remaining_seq= [x for x in seq if (x not in route)]\n",
        "    dist={}\n",
        "    finalized={}\n",
        "    for i in g.keys(): #initialize visited as false for all nodes\n",
        "        dist[i]= np.inf\n",
        "        finalized[i]=False\n",
        "    dist[s]=0\n",
        "    finalized[s]=True\n",
        "    route.append(s)\n",
        "    #remaining_seq.remove(s)\n",
        "    while s != end:\n",
        "        adj=[]\n",
        "        for u in list(g[s].keys())  : #for every neighbor of s\n",
        "            if u in g:\n",
        "                if finalized[u]==False: #if it's not finalized\n",
        "                    adj.append(u) #add to adjacent nodes which aren't finalized, then update distance\n",
        "                    x=dist[s]+g[s][u]['weight']\n",
        "                    if dist[u]>x:\n",
        "                        dist[u]=x\n",
        "        for k in adj:\n",
        "            if k==end: # if the end node is adjacent\n",
        "                route.append(k) #add end to route, then end\n",
        "                return (route)\n",
        "        if len(adj)==0: #if we reach a leaf\n",
        "            route.remove(s) #remove it\n",
        "            s=route[-1] #return to previous node\n",
        "            route.remove(s) #remove duplicate of previous node\n",
        "        else:\n",
        "            m=[k for k, v in dist.items() if v ==min(dist[a] for a in adj)] #get node/nodes that has/have minimum distance\n",
        "            m=[k for k in m if (finalized[k]==False and k in adj)] #remove the ones not adjacent or finalized\n",
        "            s=m[-1] #take last one\n",
        "        finalized[s]=True\n",
        "        route.append(s)\n",
        "        adj=[]\n",
        "    return(route)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa5289d1-b5db-48b5-9943-805caae59b1d",
      "metadata": {
        "id": "fa5289d1-b5db-48b5-9943-805caae59b1d"
      },
      "outputs": [],
      "source": [
        "def in_same_component(x,y,g): # to check if nodes x and y are in the same connected component in graph g\n",
        "    neighbors=[x]\n",
        "    for i in neighbors:\n",
        "        for u in list(merged_Graphs[i].keys()):\n",
        "            if u not in neighbors:\n",
        "                if u in g:\n",
        "                    neighbors.append(u)\n",
        "    if y in neighbors:\n",
        "        return True\n",
        "    return False\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fb47dac-622b-4727-929b-9a5c01c3ad70",
      "metadata": {
        "id": "9fb47dac-622b-4727-929b-9a5c01c3ad70"
      },
      "outputs": [],
      "source": [
        "def shortest_ordered_route(initTime, endTime, seq, start,end): #take p_1 (or p_j) and p_n as input\n",
        "    g=nx.Graph(createGraph(initTime, endTime, merged_Graphs))\n",
        "    route=[]\n",
        "    route.extend(dijkstra(g,start,seq[0]))\n",
        "    for i in range(0,len(seq)-1):\n",
        "        route.extend(dijkstra(g,seq[i],seq[i+1])[1:])\n",
        "    route.extend(dijkstra(g,seq[-1],end)[1:])\n",
        "    return(route)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6080745-6c5b-46ac-9af9-323e2d94caa8",
      "metadata": {
        "id": "d6080745-6c5b-46ac-9af9-323e2d94caa8"
      },
      "outputs": [],
      "source": [
        "def graph_fun3(a2q,c2a,c2q,initTime,endTime):\n",
        "    a2q_fun3=[i for i in a2q if initTime <=dt.utcfromtimestamp(int(a2q[i][2])).strftime('%Y-%m-%d') <=endTime]\n",
        "    c2a_fun3=[i for i in c2a if initTime <=dt.utcfromtimestamp(int(c2a[i][2])).strftime('%Y-%m-%d') <=endTime]\n",
        "    c2q_fun3=[i for i in c2q if initTime <=dt.utcfromtimestamp(int(c2q[i][2])).strftime('%Y-%m-%d') <=endTime]\n",
        "    g=mergeGraphs([a2q_fun3,c2a_fun3,c2q_fun3])\n",
        "    return g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a6d3a3a-f216-4ba9-9dba-59401115d01d",
      "metadata": {
        "id": "9a6d3a3a-f216-4ba9-9dba-59401115d01d"
      },
      "outputs": [],
      "source": [
        "def shortest_ordered_route(initTime,endTime, seq, start, end):\n",
        "    g=graph_fun3(a2q,c2a,c2q,initTime,endTime)\n",
        "    if in_same_component(start,end,g)==True:\n",
        "        route=[]\n",
        "        route.extend(dijkstra(g,start,seq[0]))\n",
        "        for i in range(0,len(seq)-1):\n",
        "            route.extend(dijkstra(g,seq[i],seq[i+1])[1:])\n",
        "        route.extend(dijkstra(g,seq[-1],end)[1:])\n",
        "        return(route)\n",
        "    return(print(\"Not possible\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7b6b187-a7f9-40e1-8c04-f99c62f4c784",
      "metadata": {
        "id": "a7b6b187-a7f9-40e1-8c04-f99c62f4c784",
        "outputId": "d64281ab-b8d1-46fa-8fb7-320b11c7a0e4"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "shortest_ordered_route() missing 1 required positional argument: 'end'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-65-e76b540cbaac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mshortest_ordered_route\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerged_Graphs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m404\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1982\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m: shortest_ordered_route() missing 1 required positional argument: 'end'"
          ]
        }
      ],
      "source": [
        "shortest_ordered_route(, [404],9,1982)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51cbfc66-7fa6-40ad-a217-293ad1ef6dbe",
      "metadata": {
        "id": "51cbfc66-7fa6-40ad-a217-293ad1ef6dbe",
        "outputId": "ad3e7195-f249-4270-f29b-65c89b01de61"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'1970-01-01 00-00-07'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dt.utcfromtimestamp(int(c2q[len(c2q)-1][2])).strftime('%Y-%m-%d %H-%M-%S')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae9dbcbf-785e-4829-93df-1260a52b87fd",
      "metadata": {
        "id": "ae9dbcbf-785e-4829-93df-1260a52b87fd",
        "outputId": "e85c1b79-99cd-4b23-a759-8cb9a73d0e4b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'1970-01-01 00-00-05'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dt.utcfromtimestamp(int(c2q[0][2])).strftime('%Y-%m-%d %H-%M-%S')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "181e1069-17f0-4edf-9011-747d2b132e9b",
      "metadata": {
        "id": "181e1069-17f0-4edf-9011-747d2b132e9b"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "HW5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}